{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the work process we performed in order to create the data to be used with NetoworkX & Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../') # Needed to import the DATES_STRINGS constant from a Python file.\n",
    "from init_data import DATES_STRINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the base DF to use in the creation of the nodes & edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>ukraine_relevance</th>\n",
       "      <th>russia_relevance</th>\n",
       "      <th>pointers</th>\n",
       "      <th>20180401-20180501</th>\n",
       "      <th>20180501-20180601</th>\n",
       "      <th>20190901-20191001</th>\n",
       "      <th>20191001-20191101</th>\n",
       "      <th>20220101-20220201</th>\n",
       "      <th>20220201-20220301</th>\n",
       "      <th>total_relevance</th>\n",
       "      <th>id</th>\n",
       "      <th>pointers_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ukrainia</td>\n",
       "      <td>437</td>\n",
       "      <td>135</td>\n",
       "      <td>Architecture of Poland, Great Purge, Mykola Kh...</td>\n",
       "      <td>218</td>\n",
       "      <td>173</td>\n",
       "      <td>185</td>\n",
       "      <td>161</td>\n",
       "      <td>394</td>\n",
       "      <td>1331</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>[216, 100, 625, 62, 86, 287, 515, 306, 1189, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>436</td>\n",
       "      <td>135</td>\n",
       "      <td>Architecture of Poland, Great Purge, Mykola Kh...</td>\n",
       "      <td>228629</td>\n",
       "      <td>259346</td>\n",
       "      <td>320373</td>\n",
       "      <td>305501</td>\n",
       "      <td>1342625</td>\n",
       "      <td>10093079</td>\n",
       "      <td>571</td>\n",
       "      <td>1</td>\n",
       "      <td>[216, 100, 625, 62, 86, 287, 515, 306, 1189, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>War in Donbass</td>\n",
       "      <td>368</td>\n",
       "      <td>306</td>\n",
       "      <td>Soledar, Kyiv Post, Post-Soviet conflicts, Tri...</td>\n",
       "      <td>72012</td>\n",
       "      <td>79062</td>\n",
       "      <td>77510</td>\n",
       "      <td>78256</td>\n",
       "      <td>232111</td>\n",
       "      <td>1185121</td>\n",
       "      <td>674</td>\n",
       "      <td>2</td>\n",
       "      <td>[143, 194, 58, 762, 515, 1518, 445, 161, 16, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RussiaâUkraine relations</td>\n",
       "      <td>349</td>\n",
       "      <td>332</td>\n",
       "      <td>Lazar Kaganovich, Belarusians, Rivne Nuclear P...</td>\n",
       "      <td>7618</td>\n",
       "      <td>7754</td>\n",
       "      <td>12557</td>\n",
       "      <td>10797</td>\n",
       "      <td>131310</td>\n",
       "      <td>1836700</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>[71, 424, 149, 1329, 105, 568, 3386, 1781, 267...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ukrainian language</td>\n",
       "      <td>346</td>\n",
       "      <td>129</td>\n",
       "      <td>Russian Empire Census, Great Purge, Turkic peo...</td>\n",
       "      <td>35159</td>\n",
       "      <td>40111</td>\n",
       "      <td>35751</td>\n",
       "      <td>38397</td>\n",
       "      <td>77086</td>\n",
       "      <td>431072</td>\n",
       "      <td>475</td>\n",
       "      <td>4</td>\n",
       "      <td>[143, 121, 287, 515, 235, 1517, 149, 714, 622,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Label  ukraine_relevance  russia_relevance  \\\n",
       "0                    Ukrainia                437               135   \n",
       "1                     Ukraine                436               135   \n",
       "2              War in Donbass                368               306   \n",
       "3  RussiaâUkraine relations                349               332   \n",
       "4          Ukrainian language                346               129   \n",
       "\n",
       "                                            pointers  20180401-20180501  \\\n",
       "0  Architecture of Poland, Great Purge, Mykola Kh...                218   \n",
       "1  Architecture of Poland, Great Purge, Mykola Kh...             228629   \n",
       "2  Soledar, Kyiv Post, Post-Soviet conflicts, Tri...              72012   \n",
       "3  Lazar Kaganovich, Belarusians, Rivne Nuclear P...               7618   \n",
       "4  Russian Empire Census, Great Purge, Turkic peo...              35159   \n",
       "\n",
       "   20180501-20180601  20190901-20191001  20191001-20191101  20220101-20220201  \\\n",
       "0                173                185                161                394   \n",
       "1             259346             320373             305501            1342625   \n",
       "2              79062              77510              78256             232111   \n",
       "3               7754              12557              10797             131310   \n",
       "4              40111              35751              38397              77086   \n",
       "\n",
       "   20220201-20220301  total_relevance  id  \\\n",
       "0               1331              572   0   \n",
       "1           10093079              571   1   \n",
       "2            1185121              674   2   \n",
       "3            1836700              681   3   \n",
       "4             431072              475   4   \n",
       "\n",
       "                                        pointers_ids  \n",
       "0  [216, 100, 625, 62, 86, 287, 515, 306, 1189, 1...  \n",
       "1  [216, 100, 625, 62, 86, 287, 515, 306, 1189, 1...  \n",
       "2  [143, 194, 58, 762, 515, 1518, 445, 161, 16, 2...  \n",
       "3  [71, 424, 149, 1329, 105, 568, 3386, 1781, 267...  \n",
       "4  [143, 121, 287, 515, 235, 1517, 149, 714, 622,...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../05_most_relevant_db/most_relevant_values.csv'\n",
    "relevant_df = pd.read_csv(file_path, index_col=0)\n",
    "relevant_df[DATES_STRINGS] = relevant_df[DATES_STRINGS].astype(int) # Change types of columns from float to int\n",
    "relevant_df['id'] = relevant_df.index # Create an ID column for Gephi's usage\n",
    "relevant_df.rename(columns={'value': 'Label'}, inplace=True) # Replace column name for Gephi's format\n",
    "pointers_set = set(relevant_df['Label']) # Unique set of pointers for future usage.\n",
    "\n",
    "def convert_pointers_to_ids(pointers_string):\n",
    "  # This function converts pointers from a list of string to a list of pointers,\n",
    "  # in order to minimize the size of the files.\n",
    "  pointers_list = pointers_string.split(', ') # Create a list of strings from the pointers\n",
    "  pointers_in_df_set = set(pointers_list) & set(pointers_set) # Leave only the pointers which exist under the Labels column.\n",
    "  pointers_ids = [relevant_df.loc[relevant_df['Label'] == pointer, 'id'].iloc[0] for pointer in pointers_in_df_set] # Convert to a list of ids.\n",
    "  return pointers_ids\n",
    "\n",
    "relevant_df['pointers_ids'] = relevant_df['pointers'].apply(convert_pointers_to_ids)\n",
    "relevant_df.sort_values('id', inplace=True)\n",
    "relevant_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Nodes & Edges datasets for every pageviews dates range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edges_df_from_nodes_df(nodes_df):\n",
    "    edges_dict = {\"Source\": [], \"Target\": []} # Dict which will be used to generate the DF\n",
    "\n",
    "    values = nodes_df['id'].to_list() # Get a list of all the values\n",
    "    values_set = set(values) # Create a set of unique values in this DF\n",
    "    # Create a list of lists, which will contain all of the pointers:\n",
    "    pointers = nodes_df['pointers_ids'] #.apply(lambda x: x.split(\", \")).to_list()\n",
    "    for i in range(len(values)): # Run through all indexes of values\n",
    "        pointers_in_df_set = set(values_set) & set(pointers.iloc[i]) # Make sure there aren't any pointers which don't have matching values in this DF\n",
    "        for item in pointers_in_df_set: # and on each item on every pointers sublist\n",
    "            # if item in values:   # if the item on the pointers sublist is on the values list\n",
    "            edges_dict[\"Source\"].append(values[i]) # Add the value as the source\n",
    "            edges_dict[\"Target\"].append(item)      # and the item as the target\n",
    "\n",
    "    edges_df = pd.DataFrame(edges_dict) # Create a dict with two columns - 'Source' & 'Target'\n",
    "    return edges_df\n",
    "\n",
    "def create_nodes_df_for_date_range(df, date_string):\n",
    "     # Get the relevant columns from the base DF where the pageviews aren't zero:\n",
    "    nodes_df = df[['id', 'Label', 'total_relevance', date_string, 'pointers_ids']][df[date_string] != 0].rename(columns={date_string: 'pageviews'})\n",
    "    return nodes_df\n",
    "\n",
    "# Create two dictionaries with the dates range as the keys and the corresponding DFs as the values:\n",
    "nodes = {dates_string: create_nodes_df_for_date_range(relevant_df, dates_string) for dates_string in DATES_STRINGS}\n",
    "edges = {dates_string: create_edges_df_from_nodes_df(nodes[dates_string]) for dates_string in DATES_STRINGS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the datasets into CSVs to be used inside of Gephi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dates_string, nodes_df in nodes.items(): # Create all of the Nodes CSVs based on the DFs\n",
    "  nodes_df.iloc[:,:-1].to_csv(f'{dates_string}_nodes.csv', index=False, encoding='utf-8')\n",
    "for dates_string, edges_df in edges.items(): # Create all of the Edges CSVs based on the DFs\n",
    "  edges_df.to_csv(f'{dates_string}_edges.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c39a25059b35fbb5772bfe03bb6a8fd01f1555b924b3683037b7bea84769da4f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
